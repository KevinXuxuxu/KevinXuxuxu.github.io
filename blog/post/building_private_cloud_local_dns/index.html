<!DOCTYPE html>
<html lang="en">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <link id="spectre" rel="stylesheet" href="/static/style/spectre.css">
        <link rel="stylesheet" href="/static/style/pygments_style.css">

        <script src="/static/script/color_theme.js"></script>
        <script>
            init_color_theme();
        </script>

        <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
    <title>Building Private Cloud: Local DNS</title>

    <style>
        /* Initially hide the element */
        .hidden {
          display: none;
        }
        
        /* Show the element when it's hovered over */
        h3:hover .hidden {
          display: inline-block;
        }
        h4:hover .hidden {
          display: inline-block;
        }
        h5:hover .hidden {
          display: inline-block;
        }
    </style>

        <link rel="apple-touch-icon" sizes="180x180" href="/static/favicon_io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/static/favicon_io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/static/favicon_io/favicon-16x16.png">
        <link rel="manifest" href="/static/favicon_io/site.webmanifest">
    </head>
    <body>
        <div class="main container grid-lg">
            <header class="navbar">
                <section class="navbar-section">
                </section>
                <section class="navbar-section">
                    <label id="color-switch" class="form-switch">
                        <input id="theme-checkbox" type="checkbox" onclick="switch_color_theme();" disabled>
                        <i class="form-icon"></i> <p id="moon">⏳</p>
                    </label>
                </section>
            </header>
            <header class="column col-sm-12 col-md-10 col-8">
                
    <figure class="avatar avatar-sm">
        <img src="/static/favicon_io/android-chrome-192x192.png" alt="avatar">
    </figure>&nbsp;
    <a href="/">fzxu's Blog</a>
    <h1 class="heading-index">Building Private Cloud: Local DNS</h1>

    <p class="text-gray">
        <small>2024-02-11 02:54:12</small>
        <span class="chip bg-secondary"><a href="/blog/category/tech/" class="text-primary">tech</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/k8s/" class="text-dark">k8s</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/Private Cloud/" class="text-dark">Private Cloud</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/Network/" class="text-dark">Network</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/DNS/" class="text-dark">DNS</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/CoreDNS/" class="text-dark">CoreDNS</a></span>
        
    </p>

            </header>
                
            <main class="content columns">
                <div class="column col-sm-12 col-md-10 col-8">
                    
    
    <p>In <a href="(/blog/post/building_private_cloud_hosting_web_service/#up_next">a previous post</a>), I touched on this weird problem where I can't access anything hosted in my cluster from my home network, but it works perfectly from outside. It's been driving me crazy – at one point, I even thought my whole Traefik setup was fried. (Honestly, who'd think to turn off their phone's WiFi to troubleshoot a home network problem?)</p>
<p>My solution uses the <a href="https://coredns.io/">CoreDNS</a> service (which comes with k3s) as a local DNS server. This lets me resolve inter-cluster service names directly to my cluster IP, bypassing whatever strange routing issue was happening before. As a bonus, having a local DNS makes it super easy to set up custom domain names and TLS for internal services.</p>
<p>So let's get right into it.</p>
<h4 id="coredns_service">CoreDNS Service&nbsp;<a class="hidden" tabindex="-1" href="#coredns_service" style="font-size: .8rem"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 8 8"><path fill="currentColor" d="M5.88.03a1.9 1.9 0 0 0-.53.09c-.27.1-.53.25-.75.47a.5.5 0 1 0 .69.69c.11-.11.24-.17.38-.22c.35-.12.78-.07 1.06.22c.39.39.39 1.04 0 1.44l-1.5 1.5c-.44.44-.8.48-1.06.47c-.26-.01-.41-.13-.41-.13a.5.5 0 1 0-.5.88s.34.22.84.25c.5.03 1.2-.16 1.81-.78l1.5-1.5A1.98 1.98 0 0 0 6.44.07C6.26.03 6.06.03 5.88.04zm-2 2.31c-.5-.02-1.19.15-1.78.75L.6 4.59a1.98 1.98 0 0 0 0 2.81c.56.56 1.36.72 2.06.47c.27-.1.53-.25.75-.47a.5.5 0 1 0-.69-.69c-.11.11-.24.17-.38.22c-.35.12-.78.07-1.06-.22c-.39-.39-.39-1.04 0-1.44l1.5-1.5c.4-.4.75-.45 1.03-.44c.28.01.47.09.47.09a.5.5 0 1 0 .44-.88s-.34-.2-.84-.22z"/></svg></a></h4>
<p>CoreDNS is an <a href="https://docs.k3s.io/networking#coredns">important component</a> of the k3s network infrastructure, serving as the <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">cluster DNS</a> of the k8s system. We can check the existing deployment status of the service in the <code>kube-system</code> namespace:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl get deployment -n kube-system -o wide
NAME                     READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS               IMAGES                                    SELECTOR
...
coredns                  <span class="m">1</span>/1     <span class="m">1</span>            <span class="m">1</span>           53d     coredns                  rancher/mirrored-coredns-coredns:1.10.1   k8s-app<span class="o">=</span>kube-dns

$ kubectl get pod -n kube-system
NAME                                      READY   STATUS      RESTARTS   AGE
...
coredns-6799fbcd5-wn6pm                   <span class="m">1</span>/1     Running     <span class="m">0</span>          22h

$ kubectl describe pod -n kube-system coredns
Name:                 coredns-6799fbcd5-wn6pm
Namespace:            kube-system
Priority:             <span class="m">2000000000</span>
Priority Class Name:  system-cluster-critical
Service Account:      coredns
...
Containers:
  coredns:
    ...
    Ports:         <span class="m">53</span>/UDP, <span class="m">53</span>/TCP, <span class="m">9153</span>/TCP
    Host Ports:    <span class="m">0</span>/UDP, <span class="m">0</span>/TCP, <span class="m">0</span>/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    ...
    Mounts:
      /etc/coredns from config-volume <span class="o">(</span>ro<span class="o">)</span>
      /etc/coredns/custom from custom-config-volume <span class="o">(</span>ro<span class="o">)</span>
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-x77ml <span class="o">(</span>ro<span class="o">)</span>
...
Volumes:
  config-volume:
    Type:      ConfigMap <span class="o">(</span>a volume populated by a ConfigMap<span class="o">)</span>
    Name:      coredns
    Optional:  <span class="nb">false</span>
  custom-config-volume:
    Type:      ConfigMap <span class="o">(</span>a volume populated by a ConfigMap<span class="o">)</span>
    Name:      coredns-custom
    Optional:  <span class="nb">true</span>
  kube-api-access-x77ml:
    Type:                     Projected <span class="o">(</span>a volume that contains injected data from multiple sources<span class="o">)</span>
    TokenExpirationSeconds:   <span class="m">3607</span>
    ConfigMapName:            kube-root-ca.crt
    ConfigMapOptional:        &lt;nil&gt;
    DownwardAPI:              <span class="nb">true</span>
...
</code></pre>
</div><p>From the config we have important pieces of information:</p>
<ul>
<li>CoreDNS has very high priority and is in <code>system-cluster-critical</code> priority class.</li>
<li>CoreDNS is opening port <code>53</code> on UDP and TCP for the main service, and port <code>9153</code> for metrics. <code>53</code> is the default port used to serve most DNS requests.</li>
<li>The main configuration source is <code>/etc/coredns/Corefile</code>, which is mounted from a k8s <code>ConfigMap</code> named <code>coredns</code>. But there're 2 other volumes mounted:<ul>
<li><code>coredns-custom</code>, which is used for custom DNS rules, which will be covered later.</li>
<li><code>kube-root-ca.crt</code> which is the k8s root ca provider. The volume type is <code>Projected</code> which means that the content inside is managed by other service and subject to change.</li>
</ul>
</li>
</ul>
<h4 id="the_corefile">The Corefile&nbsp;<a class="hidden" tabindex="-1" href="#the_corefile" style="font-size: .8rem"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 8 8"><path fill="currentColor" d="M5.88.03a1.9 1.9 0 0 0-.53.09c-.27.1-.53.25-.75.47a.5.5 0 1 0 .69.69c.11-.11.24-.17.38-.22c.35-.12.78-.07 1.06.22c.39.39.39 1.04 0 1.44l-1.5 1.5c-.44.44-.8.48-1.06.47c-.26-.01-.41-.13-.41-.13a.5.5 0 1 0-.5.88s.34.22.84.25c.5.03 1.2-.16 1.81-.78l1.5-1.5A1.98 1.98 0 0 0 6.44.07C6.26.03 6.06.03 5.88.04zm-2 2.31c-.5-.02-1.19.15-1.78.75L.6 4.59a1.98 1.98 0 0 0 0 2.81c.56.56 1.36.72 2.06.47c.27-.1.53-.25.75-.47a.5.5 0 1 0-.69-.69c-.11.11-.24.17-.38.22c-.35.12-.78.07-1.06-.22c-.39-.39-.39-1.04 0-1.44l1.5-1.5c.4-.4.75-.45 1.03-.44c.28.01.47.09.47.09a.5.5 0 1 0 .44-.88s-.34-.2-.84-.22z"/></svg></a></h4>
<p>Now let's take a look at the <code>Corefile</code> used to configure the DNS behaviors:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl describe configmap coredns -n kube-system
Name:         coredns
Namespace:    kube-system
...
<span class="nv">Data</span>
<span class="o">====</span>
Corefile:
----
.:53 <span class="o">{</span>
    errors
    health
    ready
    kubernetes cluster.local <span class="k">in</span>-addr.arpa ip6.arpa <span class="o">{</span>
      pods insecure
      fallthrough <span class="k">in</span>-addr.arpa ip6.arpa
    <span class="o">}</span>
    hosts /etc/coredns/NodeHosts <span class="o">{</span>
      ttl <span class="m">60</span>
      reload 15s
      fallthrough
    <span class="o">}</span>
    prometheus :9153
    forward . /etc/resolv.conf
    cache <span class="m">30</span>
    loop
    reload
    loadbalance
    import /etc/coredns/custom/*.override
<span class="o">}</span>
import /etc/coredns/custom/*.server

NodeHosts:
----
<span class="m">192</span>.168.0.10 rpicm4n1
<span class="m">192</span>.168.0.11 rpicm4n2
<span class="m">192</span>.168.0.12 rpicm4n3
<span class="m">192</span>.168.0.13 rk1
...
</code></pre>
</div><p>The <code>Corefile</code> itself has only one rule that starts with <code>.:53</code>, which means this rule resolves DNS requests to port <code>53</code> for all domains. Within it are a few important components:</p>
<ul>
<li><code>kubernetes</code> is <a href="https://coredns.io/plugins/kubernetes/">the plugin</a> used for k8s service discovery, just leave it there so that nothing gets broken.</li>
<li><code>hosts</code> <a href="https://coredns.io/plugins/hosts/">plugin</a> reads a hosts file and use that for domain resolution. For now it read the file <code>/etc/coredns/NodeHosts</code> whose content is from the same config map. We'll be mostly changing this for now.</li>
<li><code>forward</code> <a href="https://coredns.io/plugins/forward/">plugin</a> defines the behavior that delegates name resolution to other nameservers. In this case it forwards requests to whatever server that's in <code>/etc/resolv.conf</code>, which should be populated by the containers network environment. For a homelab, that's mostly being configured by your ISP.</li>
<li>Custom plugins in the main rule is imported from <code>/etc/coredns/custom/*.override</code> and custom rules are imported from <code>/etc/coredns/custom/*.server</code>, which is not configured by default but is something to consider if you want to do more fancy stuff.</li>
</ul>
<p>To edit this existing <code>ConfigMap</code>, use the following command:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl edit configmap coredns -n kube-system
</code></pre>
</div><p>This will open a default commandline editor for you to change the content. To solve my problem, all I need is to resolve all my external services to the master node IP by adding the following lines in the <code>NodeHosts</code> section:</p>
<div class="highlight">
    <pre class="code" data-lang="text"><span></span><code>192.168.0.10    service1.example.com
192.168.0.10    service2.example.com
192.168.0.10    service.local.example.com
</code></pre>
</div><p>Note that the &quot;external&quot; in this context means &quot;external of the cluster&quot;. So we will need to add here even if we want to host a service only locally in the home internet.</p>
<h4 id="is_that_all?">Is that all?&nbsp;<a class="hidden" tabindex="-1" href="#is_that_all?" style="font-size: .8rem"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 8 8"><path fill="currentColor" d="M5.88.03a1.9 1.9 0 0 0-.53.09c-.27.1-.53.25-.75.47a.5.5 0 1 0 .69.69c.11-.11.24-.17.38-.22c.35-.12.78-.07 1.06.22c.39.39.39 1.04 0 1.44l-1.5 1.5c-.44.44-.8.48-1.06.47c-.26-.01-.41-.13-.41-.13a.5.5 0 1 0-.5.88s.34.22.84.25c.5.03 1.2-.16 1.81-.78l1.5-1.5A1.98 1.98 0 0 0 6.44.07C6.26.03 6.06.03 5.88.04zm-2 2.31c-.5-.02-1.19.15-1.78.75L.6 4.59a1.98 1.98 0 0 0 0 2.81c.56.56 1.36.72 2.06.47c.27-.1.53-.25.75-.47a.5.5 0 1 0-.69-.69c-.11.11-.24.17-.38.22c-.35.12-.78.07-1.06-.22c-.39-.39-.39-1.04 0-1.44l1.5-1.5c.4-.4.75-.45 1.03-.44c.28.01.47.09.47.09a.5.5 0 1 0 .44-.88s-.34-.2-.84-.22z"/></svg></a></h4>
<p>Not yet. As we mentioned before, any service within the cluster has to use Traefik to expose to requesters outside of the cluster. The CoreDNS by default only serves the inter-cluster use case, so we need to add the missing pieces.</p>
<p>Remember <a href="/blog/post/building_private_cloud_hosting_web_service/#https">the piece of YAML</a> we applied for Traefik that configures the auto certificate signing with Let's Encrypt? Add the following to it and apply again. This will add a new Traefik entrypoint for port <code>53</code>:</p>
<div class="highlight">
    <pre class="code" data-lang="yaml"><span></span><code><span class="nn">...</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">valuesContent</span><span class="p">:</span> <span class="p p-Indicator">|-</span>
    <span class="no">...</span>
    <span class="no">ports:</span>
      <span class="no">dns:</span>
        <span class="no">protocol: UDP</span>
        <span class="no">port: 53</span>
        <span class="no">expose: true</span>
        <span class="no">exposedPort: 53</span>
</code></pre>
</div><p>Note that we're using UDP protocol for this entrypoint, since most DNS requests are in UDP not TCP. Then, the last pieces are the corresponding <code>Service</code> and <code>IngressRoute</code> for CoreDNS service:</p>
<div class="highlight">
    <pre class="code" data-lang="yaml"><span></span><code><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns-udp</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">UDP</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-dns</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">traefik.containo.us/v1alpha1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IngressRouteUDP</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">entryPoints</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">dns</span>
  <span class="nt">routes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">services</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
</code></pre>
</div><p>After applying this everything should work. For any device to access these services freely, change the DNS config of the wifi (or ethernet) network to favor the local DNS server, which is accessible from the cluster IP (IP of master node). Another benefit is that all the node names are also being resolved automatically. Now I can do <code>ssh rpicm4n1</code> without changing <code>/etc/hosts</code> anymore.</p>
<h4 id="conclusion">Conclusion&nbsp;<a class="hidden" tabindex="-1" href="#conclusion" style="font-size: .8rem"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 8 8"><path fill="currentColor" d="M5.88.03a1.9 1.9 0 0 0-.53.09c-.27.1-.53.25-.75.47a.5.5 0 1 0 .69.69c.11-.11.24-.17.38-.22c.35-.12.78-.07 1.06.22c.39.39.39 1.04 0 1.44l-1.5 1.5c-.44.44-.8.48-1.06.47c-.26-.01-.41-.13-.41-.13a.5.5 0 1 0-.5.88s.34.22.84.25c.5.03 1.2-.16 1.81-.78l1.5-1.5A1.98 1.98 0 0 0 6.44.07C6.26.03 6.06.03 5.88.04zm-2 2.31c-.5-.02-1.19.15-1.78.75L.6 4.59a1.98 1.98 0 0 0 0 2.81c.56.56 1.36.72 2.06.47c.27-.1.53-.25.75-.47a.5.5 0 1 0-.69-.69c-.11.11-.24.17-.38.22c-.35.12-.78.07-1.06-.22c-.39-.39-.39-1.04 0-1.44l1.5-1.5c.4-.4.75-.45 1.03-.44c.28.01.47.09.47.09a.5.5 0 1 0 .44-.88s-.34-.2-.84-.22z"/></svg></a></h4>
<p>Although I'm able to find a relatively good solution, it's still not clear what the actual problem is. My guess is that when you go &quot;the long way&quot; only trying to get back to your home public IP, the places you're from are being ignored during the jumps. Kinda like the &quot;not visiting a visited point&quot; rule in search algorithms.</p>
<p>Anyways, that's all for this post. In following posts we'll shift gears and talk about storage solutions for private cloud (if I get all the work done), as well as hosting local container registry in a k8s context. Hope you enjoy :)</p>
<p>BTW Happy Chinese New Year!</p>
<p><em>For the list of the series of blog posts about building private cloud, click <a href="/blog/tag/Private%20Cloud/">here</a>.</em></p>

    
    <i><a class="text-secondary" style="font-size: .7rem;" href="https://github.com/KevinXuxuxu/blog/blob/main/posts/building_private_cloud_local_dns.md">Markdown source</a></i>

    <script src="https://utteranc.es/client.js"
            repo="KevinXuxuxu/KevinXuxuxu.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>

                </div>
                <div class="column col-sm-12 col-md-2 col-4">
                    
                    
                </div>
            </main>
        </div>
    </body>
</html>