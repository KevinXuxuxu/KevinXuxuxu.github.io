<!DOCTYPE html>
<html lang="en">
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <link rel="stylesheet" href="/static/style/spectre.min.css">
        <link rel="stylesheet" href="/static/style/pygments_style.css">
        
    <title>Building Private Cloud: Local DNS</title>

        <link rel="apple-touch-icon" sizes="180x180" href="/static/favicon_io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/static/favicon_io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/static/favicon_io/favicon-16x16.png">
        <link rel="manifest" href="/static/favicon_io/site.webmanifest">
    </head>
    <body>
        <div class="main container grid-lg">
            <header class="column col-sm-12 col-md-10 col-8">
                <nav>
                    <ul class="breadcrumb">
                        <li class="breadcrumb-item">&nbsp;
                    </ul>
                </nav>
                
    <figure class="avatar avatar-sm">
        <img src="/static/favicon_io/android-chrome-192x192.png" alt="avatar">
    </figure>&nbsp;
    <a href="/">fzxu's Blog</a>
    <h1 class="heading-index">Building Private Cloud: Local DNS</h1>

    <p class="text-gray">
        <small>2024-02-11 02:54:12</small>
        <span class="chip bg-secondary"><a href="/blog/category/tech/" class="text-primary">tech</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/k8s/" class="text-dark">k8s</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/Private Cloud/" class="text-dark">Private Cloud</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/Network/" class="text-dark">Network</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/DNS/" class="text-dark">DNS</a></span>
        
        <span class="chip bg-gray"><a href="/blog/tag/CoreDNS/" class="text-dark">CoreDNS</a></span>
        
    </p>

            </header>
                
            <main class="content columns">
                <div class="column col-sm-12 col-md-10 col-8">
                    
    
    <p>I have mentioned a strange problem in <a href="/blog/post/building_private_cloud_hosting_web_service/">a previous post</a> that I'm not able to access services hosted in my cluster from within my home subnet, but it works from outside. This issue bothered me quite a while, once I was even considering that the whole Traefik stack is broken with this k3s distribution. (Which is reasonable because honestly who would turn off phone wifi to check home cluster network issue?)</p>
<p>The solution I have is to utilize the <a href="https://coredns.io/">CoreDNS</a> service that comes with k3s as a local self-hosted DNS server, and resolve my inter-cluster services directly to my cluster IP, so that it doesn't have to go the long way, avoiding whatever problem that way had. Plus, having a local DNS is very convenient when you have some internal service, but want cool domain name and TLS enabled for them.</p>
<p>So let's get right into it.</p>
<h4>CoreDNS Service</h4>
<p>CoreDNS is an <a href="https://docs.k3s.io/networking#coredns">important component</a> of the k3s network infrastructure, serving as the <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">cluster DNS</a> of the k8s system. We can check the existing deployment status of the service in the <code>kube-system</code> namespace:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl get deployment -n kube-system -o wide
NAME                     READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS               IMAGES                                    SELECTOR
...
coredns                  <span class="m">1</span>/1     <span class="m">1</span>            <span class="m">1</span>           53d     coredns                  rancher/mirrored-coredns-coredns:1.10.1   k8s-app<span class="o">=</span>kube-dns

$ kubectl get pod -n kube-system
NAME                                      READY   STATUS      RESTARTS   AGE
...
coredns-6799fbcd5-wn6pm                   <span class="m">1</span>/1     Running     <span class="m">0</span>          22h

$ kubectl describe pod -n kube-system coredns
Name:                 coredns-6799fbcd5-wn6pm
Namespace:            kube-system
Priority:             <span class="m">2000000000</span>
Priority Class Name:  system-cluster-critical
Service Account:      coredns
...
Containers:
  coredns:
    ...
    Ports:         <span class="m">53</span>/UDP, <span class="m">53</span>/TCP, <span class="m">9153</span>/TCP
    Host Ports:    <span class="m">0</span>/UDP, <span class="m">0</span>/TCP, <span class="m">0</span>/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    ...
    Mounts:
      /etc/coredns from config-volume <span class="o">(</span>ro<span class="o">)</span>
      /etc/coredns/custom from custom-config-volume <span class="o">(</span>ro<span class="o">)</span>
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-x77ml <span class="o">(</span>ro<span class="o">)</span>
...
Volumes:
  config-volume:
    Type:      ConfigMap <span class="o">(</span>a volume populated by a ConfigMap<span class="o">)</span>
    Name:      coredns
    Optional:  <span class="nb">false</span>
  custom-config-volume:
    Type:      ConfigMap <span class="o">(</span>a volume populated by a ConfigMap<span class="o">)</span>
    Name:      coredns-custom
    Optional:  <span class="nb">true</span>
  kube-api-access-x77ml:
    Type:                     Projected <span class="o">(</span>a volume that contains injected data from multiple sources<span class="o">)</span>
    TokenExpirationSeconds:   <span class="m">3607</span>
    ConfigMapName:            kube-root-ca.crt
    ConfigMapOptional:        &lt;nil&gt;
    DownwardAPI:              <span class="nb">true</span>
...
</code></pre>
</div><p>From the config we got important pieces of information:</p>
<ul>
<li>CoreDNS has very high priority and is in <code>system-cluster-critical</code> priority class.</li>
<li>CoreDNS is opening port <code>53</code> on UDP and TCP for the main service, and port <code>9153</code> for metrics. <code>53</code> is the default port used to serve most DNS requests.</li>
<li>The main configuration source is <code>/etc/coredns/Corefile</code>, which is mounted from a k8s <code>ConfigMap</code> named <code>coredns</code>. But there're 2 other volumes mounted:<ul>
<li><code>coredns-custom</code>, which is used for custom DNS rules, which will be covered later.</li>
<li><code>kube-root-ca.crt</code> which is the k8s root ca provider. The volume type is <code>Projected</code> which means that the content inside is managed by other service and subject to change.</li>
</ul>
</li>
</ul>
<h4>the Corefile</h4>
<p>Now let's take a look at the <code>Corefile</code> used to configure the DNS behaviors:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl describe configmap coredns -n kube-system
Name:         coredns
Namespace:    kube-system
...
<span class="nv">Data</span>
<span class="o">====</span>
Corefile:
----
.:53 <span class="o">{</span>
    errors
    health
    ready
    kubernetes cluster.local <span class="k">in</span>-addr.arpa ip6.arpa <span class="o">{</span>
      pods insecure
      fallthrough <span class="k">in</span>-addr.arpa ip6.arpa
    <span class="o">}</span>
    hosts /etc/coredns/NodeHosts <span class="o">{</span>
      ttl <span class="m">60</span>
      reload 15s
      fallthrough
    <span class="o">}</span>
    prometheus :9153
    forward . /etc/resolv.conf
    cache <span class="m">30</span>
    loop
    reload
    loadbalance
    import /etc/coredns/custom/*.override
<span class="o">}</span>
import /etc/coredns/custom/*.server

NodeHosts:
----
<span class="m">192</span>.168.0.10 rpicm4n1
<span class="m">192</span>.168.0.11 rpicm4n2
<span class="m">192</span>.168.0.12 rpicm4n3
<span class="m">192</span>.168.0.13 rk1
...
</code></pre>
</div><p>The <code>Corefile</code> itself has only one rule that starts with <code>.:53</code>, which means this rule resolves DNS requests to port <code>53</code> of all domains. Within it is a few important components:</p>
<ul>
<li><code>kubernetes</code> is <a href="https://coredns.io/plugins/kubernetes/">the plugin</a> used for k8s service discovery, just leave it there so that nothing gets broken.</li>
<li><code>hosts</code> <a href="https://coredns.io/plugins/hosts/">plugin</a> reads a hosts file and use that for domain resolution. For now it read the file <code>/etc/coredns/NodeHosts</code> whose content is from the same config map. We'll be mostly changing this for now.</li>
<li><code>forward</code> <a href="https://coredns.io/plugins/forward/">plugin</a> defines the behavior that delegates name resolution to other nameservers. In this case it forwards requests to whatever server that's in <code>/etc/resolv.conf</code>, which should be populated by the containers network environment. For a homelab, that's mostly being configured by your ISP.</li>
<li>Custom plugins in the main rule is imported from <code>/etc/coredns/custom/*.override</code> and custom rules are imported from <code>/etc/coredns/custom/*.server</code>, which is not configured by default but is something to consider if you want to do more fancy stuff.</li>
</ul>
<p>To edit this existing <code>ConfigMap</code> we can use the following command:</p>
<div class="highlight">
    <pre class="code" data-lang="shell"><span></span><code>$ kubectl edit configmap coredns -n kube-system
</code></pre>
</div><p>This will open a default commandline editor for you to change the content. To solve my problem, all I need is to resolve all my external services to the master node IP by adding the following lines in the <code>NodeHosts</code> section:</p>
<div class="highlight">
    <pre class="code" data-lang="text"><span></span><code>192.168.0.10    service1.example.com
192.168.0.10    service2.example.com
192.168.0.10    service.local.example.com
</code></pre>
</div><p>Note that the &quot;external&quot; in this context means &quot;external of the cluster&quot;. So we will need to add here even if we want to host a service only locally in the home internet.</p>
<h4>Is that all?</h4>
<p>Not yet. As we mentioned before, any service within the cluster has to use Traefik to expose to requesters outside of the cluster. The CoreDNS by default only serves the inter-cluster use case, so we need to add the missing pieces.</p>
<p>Remember the piece of YAML (from <a href="/blog/post/building_private_cloud_hosting_web_service/">this post</a>) we applied for Traefik that configures the auto certificate signing with Let's Encrypt? Add the following to it and apply again. This will add a new Traefik entrypoint for port <code>53</code>:</p>
<div class="highlight">
    <pre class="code" data-lang="yaml"><span></span><code><span class="nn">...</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">valuesContent</span><span class="p">:</span> <span class="p p-Indicator">|-</span>
    <span class="no">...</span>
    <span class="no">ports:</span>
      <span class="no">dns:</span>
        <span class="no">protocol: UDP</span>
        <span class="no">port: 53</span>
        <span class="no">expose: true</span>
        <span class="no">exposedPort: 53</span>
</code></pre>
</div><p>Note that we're using UDP protocol for this entrypoint, since most DNS requests are in UDP not TCP. Then, the last pieces are the corresponding <code>Service</code> and <code>IngressRoute</code> for CoreDNS service:</p>
<div class="highlight">
    <pre class="code" data-lang="yaml"><span></span><code><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns-udp</span>
      <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">UDP</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
      <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
  <span class="nt">selector</span><span class="p">:</span>
    <span class="nt">k8s-app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-dns</span>
<span class="nn">---</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">traefik.containo.us/v1alpha1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IngressRouteUDP</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">entryPoints</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">dns</span>
  <span class="nt">routes</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">services</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
      <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">53</span>
</code></pre>
</div><p>After applying this everything should work. For any device to access these services freely, change the DNS config of the wifi (or ethernet) network to favor the local DNS server, which is accessible from the cluster IP (IP of master node). Another benefit is that all the node names are also being resolved automatically. Now I can do <code>ssh rpicm4n1</code> without changing <code>/etc/hosts</code> anymore.</p>
<h4>Conclusion</h4>
<p>Although I'm able to find a relatively good solution, it's still not clear what the actual problem is. My guess is that when you go &quot;the long way&quot; only trying to get back to your home public IP, the places you're from are being ignored during the jumps. Kinda like the &quot;not visiting a visited point&quot; rule in search algorithms.</p>
<p>Anyways, that's all for this post. In following posts we'll shift gears and talk about storage solutions for private cloud (if I get all the work done), as well as hosting local container registry in a k8s context. Hope you enjoy :)</p>
<p>BTW Happy Chinese New Year!</p>

    
    <i><a class="text-secondary" style="font-size: .7rem;" href="https://github.com/KevinXuxuxu/blog/blob/main/posts/building_private_cloud_local_dns.md">Markdown source</a></i>

    <script src="https://utteranc.es/client.js"
            repo="KevinXuxuxu/KevinXuxuxu.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>

                </div>
                <div class="column col-sm-12 col-md-2 col-4">
                    
                    
                </div>
            </main>
        </div>
    </body>
</html>